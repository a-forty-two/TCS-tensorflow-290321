{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCS 02 Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5GcrrdD6nYjyvK1I3mzcL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4_4zT8qBOCD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import string\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKquQCLGBm8Q",
        "outputId": "88e0d879-ab0c-45ee-e27b-6c0158d59682"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX34X3XiBtDN",
        "outputId": "c94fcb31-4f46-42e7-aa6f-2052f7826251"
      },
      "source": [
        "# data source at https://ai.stanford.edu/~amaas/data/sentiment/\n",
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url, untar=True, cache_dir='.', cache_subdir='')\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7TCa-rcCfKz",
        "outputId": "8f4a1c36-5be9-4d7d-b567-20e77431c69d"
      },
      "source": [
        "os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'imdb.vocab', 'README', 'train', 'imdbEr.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llUHZ4KYCx_k",
        "outputId": "35c74636-05a6-4f76-d33c-2981a52acd7f"
      },
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labeledBow.feat',\n",
              " 'urls_neg.txt',\n",
              " 'unsup',\n",
              " 'urls_unsup.txt',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'urls_pos.txt',\n",
              " 'unsupBow.feat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDyVzzi_C8er"
      },
      "source": [
        "sampleFile = os.path.join(train_dir, 'pos/1181_9.txt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUm58E6KDWbk",
        "outputId": "69bcb3ce-94aa-48f9-efc8-41b9fe4312a0"
      },
      "source": [
        "with open(sampleFile) as f:\n",
        "  print(f.read())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_yrukNlDZ_W"
      },
      "source": [
        "# remove all unsupported types\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIp2ydzBDpY2",
        "outputId": "7383caab-a2b5-40ff-e527-6e879bb4e3d9"
      },
      "source": [
        "batch_size = 32\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zblF8kHEDb_",
        "outputId": "5d490879-ef2f-4ae8-d916-5d2ac4faf6e9"
      },
      "source": [
        "raw_train_ds.take(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAEHne1gHTB6",
        "outputId": "ccea9ebf-178b-4aa2-cae8-6f389575b57a"
      },
      "source": [
        "for text, label in raw_train_ds.take(1):\n",
        "  for i in range(5):\n",
        "    print(\"review: \", text.numpy()[i])\n",
        "    print(\"label: \", label.numpy()[i])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review:  b\"I went to see Fever Pitch with my Mom, and I can say that we both loved it. It wasn't the typical romantic comedy where someone is pining for the other, and blah blah blah... You weren't waiting for the climatic first kiss or for them to finally get together. It was more real, because you saw them through the relationship, rather than the whole movie be about them getting together. People could actually relate to the film, because it didn't seem like extraordinary circumstances, or impossible situations. It was really funny, and I think it was Jimmy Fallon's best performance. All in all... I would definitely recommend it!\"\n",
            "label:  1\n",
            "review:  b\"from the view of a NASCAR Maniac like I am, the movie is interesting. You can see many race cars from 1983. Even tough, the racing scenes are not that much realistic. But I have to admit, that I haven't seen any race before 1995, because before that time, they didn't show any NASCAR races in Germany)<br /><br />from the view of a Burt Reynolds fan like I am, the movie basically is what we are used to see from Reynolds in the 80's: Burt behind the wheel of a fast car, like in his Bandit Movies.<br /><br />If you love NASCAR and Burt Reynolds, this movie is a must-see. If you only love one of this 2 things, I also recommend to watch it. If you like neither NASCAR nor Burt Reynolds, you still should give it a chance, but remember, this movie was far away from winning an Oscar Academy Award.<br /><br />It is the typical humor of the 80's. If you like movies like the Cannonball Movies, and Police Academy, you will also like that one.\"\n",
            "label:  1\n",
            "review:  b\"This is a terrible movie, terrible script, bad direction and nonsensical ending. Also, bad performances, except from Clancy Brown who is criminally underused here, and Michael Pollard. Watching this movie was purgatory--you do it to unload enough bad movie karma to actually see a good one further down the line.<br /><br />The movie presents a father and son who look like they couldn't every possibly have been related. The part of the male lead is not well written and seems uncharismatic in this role. You can see the plot points a mile away. The actions of the female lead and that of her brother, the cop, also make no sense. So, a major action on her part at the end of the movie makes no sense script-wise.\"\n",
            "label:  0\n",
            "review:  b\"Well, well....Roeg touched a bit of a nerve there, didn't he? He was a genius while he was cataloguing his various characters' descents into psychosis for a couple of decades, but as soon as he has the bad taste to suggest that redemption (or even some good advice) might be found in the bad old Catholic church, the hipper-than-thou alternative movie crowd gets extra vicious. Worse still, Theresa Russell's character - faced with experiences that nothing in her avowedly rationalist outlook has an explanation for, is unwillingly forced to deal with those experiences on another level - that of the spiritual. You know, the realm of the ignorant and superstitious, the sort of thing that the art-house cinephiles are supposed to be above. Oh, the horror... So she finds her marriage - the idea that it might be a uniquely important commitment - affirmed by what seems uncomfortably like divine intervention. People who find this idea prima facie offensive could maybe ask themselves why they instinctively jump into attack mode at being challenged to take seriously the idea of a spiritual dimension to their lives. But they probably won't. Sure, this film has some problems, notably Talia Shire's delirious hamwork as the overwrought nun, 1950s-style attire and all. And the dialogue between Marie Davenport and the young priest in their last scene is straight out of the Spellbound School of Glib Interpretations (though Hitchcock's movie escaped similar charges due to the source of wisdom having impeccably secular credentials as a Freudian psychoanalyst). But, sadly, Nicolas Roeg appears to have copped a critical mauling as much for even asking the question as for the possible answers this film presents.\"\n",
            "label:  1\n",
            "review:  b\"I have been familiar with the fantastic book of 'Goodnight Mister Tom' for absolutely ages and it was only recently when I got the chance to watch this adaption of it. I have heard lots of positive remarks about this, so I had high hopes. Once this film had finished, I was horrified.<br /><br />This film is not a good film at all. 'Goodnight Mister Tom' was an extremely poor adaption and practically 4.5/10 of the book was missed out. Particularly, I found that a lot of the characters and some great scenes in the book were not in this. There was not much dialogue, It was rushed and far too fast-moving, but I was mostly upset by the fact that you never got to see the bonding and love between William Beech and Tom in this film which was a true let down. The casting was not all that good,either. I thought this could have been really good, but it was so different to the book! Anextremely poor adaption, one of the worst I've seen. This deserves a decent remake that'd better be 1000 times better than this pile of garbage.\"\n",
            "label:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cNDCcVlUHtlc",
        "outputId": "60ff431c-15c1-4e06-b062-424698871cc2"
      },
      "source": [
        "raw_train_ds.class_names[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'neg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "t9GKAhcjJtZD",
        "outputId": "e9fdaf13-7019-4312-8793-4c19af7e948e"
      },
      "source": [
        "raw_train_ds.class_names[1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7A6_Yb3JvCy",
        "outputId": "0bf58c21-860d-4324-82b9-51326afbe1df"
      },
      "source": [
        "raw_train_ds.__dict__ # one way-> open entire object as dictionary"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_batch_size': <tf.Tensor: shape=(), dtype=int64, numpy=32>,\n",
              " '_drop_remainder': <tf.Tensor: shape=(), dtype=bool, numpy=False>,\n",
              " '_graph_attr': <tensorflow.python.framework.ops.Graph at 0x7f5f22888710>,\n",
              " '_input_dataset': <ShuffleDataset shapes: ((), ()), types: (tf.string, tf.int32)>,\n",
              " '_options_attr': <tensorflow.python.data.ops.dataset_ops.Options at 0x7f5f2287c3d0>,\n",
              " '_self_name_based_restores': set(),\n",
              " '_self_saveable_object_factories': {},\n",
              " '_self_setattr_tracking': True,\n",
              " '_self_unconditional_checkpoint_dependencies': [TrackableReference(name='_variant_tracker', ref=<tensorflow.python.data.ops.dataset_ops._VariantTracker object at 0x7f5f23837250>)],\n",
              " '_self_unconditional_deferred_dependencies': {},\n",
              " '_self_unconditional_dependency_names': {'_variant_tracker': <tensorflow.python.data.ops.dataset_ops._VariantTracker at 0x7f5f23837250>},\n",
              " '_self_update_uid': -1,\n",
              " '_structure': (TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
              "  TensorSpec(shape=(None,), dtype=tf.int32, name=None)),\n",
              " '_variant_tensor_attr': <tf.Tensor: shape=(), dtype=variant, numpy=<unprintable>>,\n",
              " '_variant_tracker': <tensorflow.python.data.ops.dataset_ops._VariantTracker at 0x7f5f23837250>,\n",
              " 'class_names': ['neg', 'pos']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AsyXHdiJ6l7",
        "outputId": "9f6c411f-78eb-4dd2-977f-2199386f265a"
      },
      "source": [
        "print(list(dir(raw_train_ds))) # one way-> open entire object as directory"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['_GeneratorState', '__abstractmethods__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_add_variable_with_custom_getter', '_apply_options', '_as_serialized_graph', '_batch_size', '_checkpoint_dependencies', '_consumers', '_deferred_dependencies', '_drop_remainder', '_flat_shapes', '_flat_structure', '_flat_types', '_functions', '_gather_saveables_for_checkpoint', '_graph', '_graph_attr', '_handle_deferred_dependencies', '_has_captured_ref', '_input_dataset', '_inputs', '_list_extra_dependencies_for_serialization', '_list_functions_for_serialization', '_lookup_dependency', '_map_resources', '_maybe_initialize_trackable', '_name_based_attribute_restore', '_name_based_restores', '_no_dependency', '_object_identifier', '_options_attr', '_preload_simple_restoration', '_restore_from_checkpoint_position', '_self_name_based_restores', '_self_saveable_object_factories', '_self_setattr_tracking', '_self_unconditional_checkpoint_dependencies', '_self_unconditional_deferred_dependencies', '_self_unconditional_dependency_names', '_self_update_uid', '_setattr_tracking', '_shape_invariant_to_type_spec', '_single_restoration_from_checkpoint_position', '_structure', '_tf_api_names', '_tf_api_names_v1', '_trace_variant_creation', '_track_trackable', '_tracking_metadata', '_type_spec', '_unconditional_checkpoint_dependencies', '_unconditional_dependency_names', '_update_uid', '_variant_tensor', '_variant_tensor_attr', '_variant_tracker', 'apply', 'as_numpy_iterator', 'batch', 'cache', 'cardinality', 'class_names', 'concatenate', 'element_spec', 'enumerate', 'filter', 'flat_map', 'from_generator', 'from_tensor_slices', 'from_tensors', 'interleave', 'list_files', 'map', 'options', 'padded_batch', 'prefetch', 'range', 'reduce', 'repeat', 'shard', 'shuffle', 'skip', 'take', 'unbatch', 'window', 'with_options', 'zip']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__GN6qTKKDeK",
        "outputId": "34b352ad-4756-43ad-e190-25a8bc1bf3bd"
      },
      "source": [
        "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbLX5o0FLJi_",
        "outputId": "d7ec2e4e-efef-40e6-8300-8045882d33ea"
      },
      "source": [
        "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bql_cax5NXOA"
      },
      "source": [
        "# define all HPs\n",
        "max_features = 10000\n",
        "sequence_length = 250 # smaller reviews must be padded, and larger reviews must be chopped\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR4UNbWmLQwc"
      },
      "source": [
        "# get rid of all unwanted words, tokens.... such as .<br />\n",
        "\n",
        "\n",
        "def scrub_fn(text):\n",
        "  lowercase = tf.strings.lower(text)\n",
        "  strip_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  newtext = tf.strings.regex_replace(strip_html, '[%s]' % re.escape(string.punctuation), '')\n",
        "  return newtext\n",
        "\n",
        "#vectorize -> convert words into respective vectors \n",
        "vectorize_layer = TextVectorization(standardize=scrub_fn,\n",
        "                                    max_tokens= max_features,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length = sequence_length)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1cuTV9ANyqi",
        "outputId": "b3a8c62e-28af-41b2-fa41-b0886127347a"
      },
      "source": [
        "# text -only dataset, without the labels \n",
        "traintext = raw_train_ds.map(lambda x , y: x)\n",
        "#\n",
        "traintext"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: (None,), types: tf.string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lELq3v66Obev",
        "outputId": "5f1645c5-c18f-4719-e71d-a1f5cdca937a"
      },
      "source": [
        "for text in traintext.take(1):\n",
        "  for i in range(5):\n",
        "    print(\"review: \", text.numpy()[i])\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review:  b'Every scene was put together perfectly.This movie had a wonderful cast and crew. I mean, how can you have a bad movie with Robert Downey Jr. in it,none have and ever will exist. He has the ability to brighten up any movie with his amazing talent.This movie was perfect! I saw this movie sitting all alone on a movie shelf in \"Blockbuster\" and like it was calling out to me,I couldn\\'t resist picking it up and bringing it home with me. You can call me a sappy romantic, but this movie just touched my heart, not to mention made me laugh with pleasure at the same time. Even though it made me cry,I admit, at the end, the whole movie just brightened up my outlook on life thereafter.I suggested to my horror, action, and pure humor movie buff of a brother,who absolutely adored this movie. This is a movie with a good sense of feeling.It could make you laugh out loud, touch your heart, make you fall in love,and enjoy your life.Every time you purposefully walk past this movie, just be aware that you are consciously making the choice to live and feel this inspiring movie.Who knows? What if it could really happen to you?, and keep your mind open to the mystical wonders of life.'\n",
            "review:  b\"Despite its low-key release in this country, and its apparent disregard in other countries (the 'R' rating in the States can't have helped - honestly, just because HBC uses the C-word!), this is actually a fine piece of work. The sentimentality does occasionally threaten to choke it, but it's overcome by the playing of the two leads.<br /><br />It's easy to win plaudits just because you're playing a physical or mental cripple (Daniel Day-Lewis, Geoffrey Rush, Dustin Hoffman, etc.), and Helena Bonham-Carter may not quite capture the physical degradation of MND, but her vocal stretching and ruthless emotional drive compensate entirely. In fact, almost all her performance is conducted through her eyes (and what eyes!). This is an intelligent turn from an actress who is rapidly undoing her English Rose reputation, and emerging as a figure of some stature. Awards must surely follow, though not, alas, for this fine performance.<br /><br />Branagh, one feels, has never quite given his best on film (except possibly 'Hamlet', and there his playing was diluted by the large cast). Here, though, he tops his other appearances, playing to the hilt a self-loathing, unstable, ultimately lovable guy with a subtlety he hasn't always displayed, and exhibiting both intelligence and depth. In short, we believe him, just as much as we could NOT believe him as Frankenstein, as the priest in 'The Proposition', as the lawyer in 'The Gingerbread Man', even as Andrew in 'Peter's Friends'. This is surely his finest performance yet - so why could he not produce the goods much earlier?<br /><br />As a film, it looks more like a television offering, and without its stars it probably wouldn't amount to very much. But it's been a pleasure to see this pair perform their socks off like this, and I eagerly await more from them (though not 'Love's Labour's Lost'...). 8 out of 10, but Branagh and HBC get 10 out of 10.\"\n",
            "review:  b'This is probably the best television show I\\'ve ever seen. I first saw it on Comedy Central several years ago. At the time I was unaware that it had been dramatically edited and was shown out of order, and having just watched all three series in order and unedited (thank you internet and your wondrous \"series of tubes\") I am SO GLAD I rediscovered it! I think Comedy Central sort of picked and chose their way through series one and two to make a \"season\"......and I tried to get friends and family to watch it, but nobody really seemed to like it (I need new friends). So, on my own, I made the best out of it that I could. Even when I felt like it was waning a bit, I still felt compelled to continue watching. Years after when I discovered Little Britain, I immediately recognized Pauline from LoG as having influenced Marjorie in Fat Fighters. Also, I love the idea of writers who act the entire show....(not new, but done impeccably here). LB has nothing on LoG! (No offense, Matt & David....Love you)! This is indeed a darkly comedic piece of genius. Serial murder, implied cannibalism.....you name it and it\\'s probably found in this wonderful, unique piece of TV art. The location shots from the very first scene themselves are chilling and seem to beckon you to the town of Royston Vasey.....You\\'ll Never Leave! I think my favorite character would have to be Tubbs, but each character as portrayed has it\\'s own \"charm\". My least favorite was Papa Lazarous, that was until he re-surfaced in series three (clever and wholly unexpected)! It\\'s best to watch several episodes in a row as it drives the continuity and as I said before, becomes so compelling (while repulsing) that you really CAN\\'T stop watching. This is not for those with weak stomachs, kids, conservatives or Grandma (unless you\\'ve got one saucy granny)! I have always loved British TV, particularly comedies, from Monty Python to Benny Hill, Red Dwarf to Keeping Up Appearances, Absolutely Fabulous and the British originals Coupling and The Office (but not their US counterparts....sorry). This is unlike any of those in that it completely redraws the line between what\\'s funny and what\\'s just sick and twisted. Nothing, NOTHING on US TV has ever come close to this level of entertainment. US broadcast TV is so sad and lame, I can barely stand to watch ANY of it. It\\'s kind of sad that even our cable channels don\\'t have the guts to show unedited versions of this gem (your loss, Comedy Central). Thankfully there are shows like this one that come from the \"across the pond\" that redeem the entire medium every decade or so. Basic cable here in the US has been making tiny steps the last few years in confidently \"crossing lines\" with more graphic sexual content, drug use and adult language, but they are still years away from just deciding to be Adults about showing real life, adult behavior (instead of just murder obsession and blowing things up, sheesh, it\\'s like the same basic show format for the past 35 years)! Don\\'t even get me started on US sitcoms! Waste of time and lots of wasted money......did you know that \"According to Jim\" has been on the air for 10 years??? 10 YEARS?? Anyway... Watch this show, get it on DVD, do what you must and then make your friends watch it as well! You\\'ve never seen anything like it. There are three specials that I have not watched yet....I\\'m saving them to spring on my best friend next time he visits. He\\'ll watch them, even if I have to chain him up and paint him with Excrement! Lines and lines and lines and lines! Note that series three departs from one and two....the greater town seems to fall away to concentrate on newer characters, the laugh track is gone (thank bloody hell), the theme is more band and less orchestra and a bit of the story takes place outside of Royston Vasey. Don\\'t be thrown by any of that as by the end, the series has preserved the quiet perversity first demonstrated in series one and two. I think these four guys have created something sort of undefinable. Brilliant, confident and absolutely demented. You will want to re-watch it again and again. It\\'s amazing that in 5 seconds of screen time they can go from cheap sight-gag to horrifying blasphemy then end with a single actors close-up facial expression. If ever I were to meet any of the writer/performers, I\\'d implore them not to recreate it or try to top it.....I\\'d just say \"Can I help you at all?\" (Then they\\'d probably slap me, so I\\'d ask them to sign the slap-mark)! 10 out of 10'\n",
            "review:  b'First, this was a BRAVE film. I\\'ve seen Irreversible and can understand the comparisons. However, I cannot begin to understand the people who\\'ve trashed this film. I can see how the end may have come off extreme but I\\'d be lying if I didn\\'t say I wished that every guy who\\'s ever forced a woman into sex deserved exactly what Jared got. Conversely, it didn\\'t solve anything or make anything better and the fact that the film doesn\\'t pretend to is what made me appreciate it.<br /><br />The comment prior to this one called the film pathetic and claimed no adult would stick with. I certainly did and intently. I\\'m 24 years old. The way the film drags made it realistic to me. People have become so used to eye candy and fast paced plots on screen that if you ask them to concentrate too long on one brick in the foundation of a film, not only do they lose interest, they demolish whatever has been built, and call it rubbish. When in actuality it\\'s their lack of patience and comprehension that needs fine tuning and not the product of a creative mind such as Talia Lugacy\\'s.<br /><br />Rosario Dawson displayed the numbness of self-destruction flawlessly. I think she portrayed Maya pre and post assault with great ease and the transition between the two is an act I rarely ever see done well. Often times, much like the films \"aimed at teens\" mentioned in the prior comment, the effects of rape are displayed as either extremely manic and impulsive or terribly depressed, isolated and lifeless. Dawson, in my opinion, manages to perform the balancing act so many survivors fall prey to: drone-like existence in the waking hours, working some dead end job to survive (and distract) and then overindulging in vices in order to lose themselves in the haze of substance abuse rather than face what sobriety brings.<br /><br />I thought this film told the truth and I appreciated it for finally showing people a different side of rape. So many people let the end of this film devour the middle and the beginning...I believe that Maya\\'s face during the act was the end...not the act itself...not the vengeance or the meaning behind it...just her face...<br /><br />thank you'\n",
            "review:  b'I try to be very objective when I view a low budget movie. I also apply a lower weight to independent and low budget productions versus the big budget productions. I expect near flawlessness from big budget productions and their studios. Therefore I apply tougher criteria to the major studio releases. But this movie was just a dud. Period. The premise was terrible. The main character, Mary Gordano (Alicia Silverstone), was unbelievable as a high school senior with an unquenchable desire to solve crimes. There was not enough depth in her character or her acting that pulled you into her world. Also, to make this movie more mysterious, the lighting in certain scenes did not set the mood, especially in the warehouse.<br /><br />Once again another disappointing movie that I could only give three points to.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rN4MCwaOxiR"
      },
      "source": [
        "vectorize_layer.adapt(traintext)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WImprT--O3_D"
      },
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoAlVlLmPNdD",
        "outputId": "caaa2fb6-a053-47bd-adec-f1a553e843e3"
      },
      "source": [
        "# take-> active pointer rolling on the dataset\n",
        "textbatch, labelbatch = next(iter(raw_train_ds))\n",
        "firstreview , firstlabel = textbatch[0], labelbatch[0]\n",
        "print(firstreview)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'\"A young woman suffers from the delusion that she is a werewolf, based upon a family legend of an ancestor accused of and killed for allegedly being one. Due to her past treatment by men, she travels the countryside seducing and killing the men she meets. Falling in love with a kind man, her life appears to take a turn for the better when she is raped and her lover is killed by a band of thugs. Traumatized again by these latest events, the woman returns to her violent ways and seeks revenge on the thugs,\" according to the DVD sleeve\\'s synopsis.<br /><br />Rino Di Silvestro\\'s \"La lupa mannara\" begins with full frontal, writhing, moaning dance by shapely blonde Annik Borel, who (as Daniella Neseri) mistakenly believes she is a werewolf. The hottest part is when the camera catches background fire between her legs. The opening \"flashback\" reveals her hairy ancestor was (probably) a lycanthropic creature. Ms. Borel is, unfortunately, not a werewolf; she is merely a very strong lunatic.<br /><br />As a film, \"Werewolf Woman\" (in English) would have been better if Borel\\'s character really was a female werewolf; with her sexual victimization a great bit of characterization. But, as far as 1970s skin and blood flicks go, this one is hard to beat. Bouncy Borel is either nude or sexily clad throughout the film, which features a fair amount of gratuitous gore. Dazzling Dagmar Lassander (as Elena) and hunky Howard Ross (as Luca) are good supporting players.', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fri6i-0yPybV",
        "outputId": "a05c0b52-4768-489a-c63d-e399f8aac708"
      },
      "source": [
        "vectorize_text(firstreview, firstlabel)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
              " array([[   4,  181,  246, 2320,   35,    2,    1,   12,   55,    7,    4,\n",
              "         1823,  443,  718,    4,  215, 1725,    5,   33,    1, 3420,    5,\n",
              "            3,  546,   15, 8957,  108,   28,  684,    6,   39,  491, 2217,\n",
              "           32,  348,   55, 4096,    2, 4169,    1,    3,  846,    2,  348,\n",
              "           55,  879, 1387,    8,  115,   16,    4,  236,  130,   39,  116,\n",
              "          723,    6,  190,    4,  459,   15,    2,  122,   51,   55,    7,\n",
              "         3377,    3,   39, 1522,    7,  546,   32,    4, 1090,    5, 3616,\n",
              "         8981,  169,   32,  129, 2379,  650,    2,  246, 1734,    6,   39,\n",
              "         1097,  760,    3, 4972, 1087,   20,    2, 3616, 1668,    6,    2,\n",
              "          287,    1, 3658,    1,    1,    1,  990,    1,    1,  762,   16,\n",
              "          374, 7652,    1,    1,  833,   32,    1, 1941,    1,    1,   36,\n",
              "           14,    1,    1,    1, 2101,   55,    7,    4, 1823,    2,    1,\n",
              "          170,    7,   51,    2,  379, 3898,  985,  973,  188,   39, 2988,\n",
              "            2,  634, 2721, 2684,   39, 8463,    1,   13,  235,    4,    1,\n",
              "         1612, 1474,    1,    7,  460,   21,    4, 1823,   55,    7, 1516,\n",
              "            4,   52,  556, 6830,   14,    4,   19, 1823,  246,    8,  648,\n",
              "           59,   25,   74,  122,   45,    1,  106,   62,   13,    4,  638,\n",
              "         1823,   16,   39,  845,    1,    4,   86,  221,    5, 3414,   18,\n",
              "           14,  231,   14, 2311, 2595,    3,  528, 1427,  137,   11,   28,\n",
              "            7,  264,    6, 1638,    1,    1,    7,  338, 2613,   41,    1,\n",
              "         8134,  458,    2,   19,   60,  915,    4, 1234, 1137,    5, 2135,\n",
              "          594, 5842,    1,    1,   14,    1,    3, 8456, 2274, 5645,   14,\n",
              "            1,   23,   49,  679, 1787,    0,    0,    0]])>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc65piU7P5zD"
      },
      "source": [
        "# Sentiment Analysis\n",
        "# y = mx + c\n",
        "# y = weights * inputs + bias\n",
        "# y = sentiment. So if y > 0.5, sent=POS, else sent=NEG\n",
        "\n",
        "# inputs=> 10,000 words! \n",
        "# sentiment = w1*word1 + w2*word2... w10000*word10000 + bias \n",
        "# out of the above only 250 weights (w1...w10000) will be non-zero! \n",
        "\n",
        "# dictionary = [ going eating am I is he she sleeping writing and ]\n",
        "# max length = 4\n",
        "# s1-> i am writing\n",
        "# s2-> she and i and writing and eating \n",
        "# s3-> he is going \n",
        "\n",
        "# y = w1*going + w2*eating + w3*am + w4*I + w5*is + w6.... w10* and + bias \n",
        "\n",
        "# s1 = w1*0 + w2*0 + w3*123 + w4*87 + w5*0.... w9*101 + w10*0 + bias \n",
        "\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "HSadFfdoRS6F",
        "outputId": "0b372cc4-dd16-43e9-da70-0e001fcfe492"
      },
      "source": [
        "allvectors = vectorize_layer.get_vocabulary()\n",
        "allvectors[42]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'about'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "HMinDaxsRftw",
        "outputId": "189efdba-ddea-4693-f05f-6f75c68a73fb"
      },
      "source": [
        "allvectors[9042]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'owning'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFaIDK9TRogs"
      },
      "source": [
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRWq4S_Kn99q"
      },
      "source": [
        "# Data set tuning\n",
        "# When data is picked from the disk-> its loaded into memory\n",
        "# IN-MEMORY-> caching\n",
        "# Model execution overlap with data processing!-> prefetching!\n",
        "\n",
        "#Autotuning\n",
        "autotune = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=autotune)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=autotune)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=autotune)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrtNCgYbopCx"
      },
      "source": [
        "Learning-> Fully Connected Layers\n",
        "# 2 models\n",
        "\n",
        "# preprocess text -> Dense \n",
        "\n",
        "# preprocess text -> Dense + Dense \n",
        "\n",
        "how to preprocess the text?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8lGW8eholcp"
      },
      "source": [
        "HP_embedding_dim = 16\n",
        "HP_dropout = 0.2 # regularization \n",
        "HP_hidden_outputs = 32\n",
        "HP_epochs= 20\n",
        "HP_batch_size = 32\n",
        "HP_vocab_size = 10000"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOcuNLpKrHvE"
      },
      "source": [
        "\n",
        "from tensorflow.keras import layers, losses, preprocessing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "l1 = tf.keras.layers.Embedding(HP_vocab_size, HP_embedding_dim)\n",
        "l2 = layers.GlobalAveragePooling1D()\n",
        "l3 = layers.Dense(HP_hidden_outputs, activation=\"relu\")\n",
        "l4 = layers.Dense(1)\n",
        "layers_m1 = [l1,l2,l3,l4]\n",
        "model = tf.keras.Sequential(layers_m1)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnQFiFeDr0K1",
        "outputId": "eddd7152-62a2-443c-8355-3ae44facb9e3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,577\n",
            "Trainable params: 160,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uRJFvWssgdT"
      },
      "source": [
        "# Dense -> input * output + output \n",
        "# Dense -> inputs * vector_size + bias\n",
        "# Dense -> 16*32 + 32 = 544\n",
        "# Dense -> 32 * 1 + 1 = 33\n",
        "# for embedding vector lookup-> bias = 0\n",
        "# EMbedding -> input * output -> 10000 * 16 => 160,000"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pChWPQIQtR66"
      },
      "source": [
        "model.compile(loss= losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer='adam',\n",
        "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufOt8bQ9tqst",
        "outputId": "764af66d-0c4c-49fa-b9ee-6d7ce2258a1e"
      },
      "source": [
        "history = model.fit(train_ds, validation_data=val_ds, epochs=HP_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6282 - binary_accuracy: 0.6577 - val_loss: 0.3437 - val_binary_accuracy: 0.8602\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3022 - binary_accuracy: 0.8793 - val_loss: 0.2934 - val_binary_accuracy: 0.8802\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2267 - binary_accuracy: 0.9159 - val_loss: 0.2903 - val_binary_accuracy: 0.8806\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1844 - binary_accuracy: 0.9318 - val_loss: 0.3014 - val_binary_accuracy: 0.8808\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1532 - binary_accuracy: 0.9473 - val_loss: 0.3202 - val_binary_accuracy: 0.8814\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1282 - binary_accuracy: 0.9582 - val_loss: 0.3444 - val_binary_accuracy: 0.8782\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1071 - binary_accuracy: 0.9673 - val_loss: 0.3721 - val_binary_accuracy: 0.8774\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0890 - binary_accuracy: 0.9733 - val_loss: 0.4039 - val_binary_accuracy: 0.8766\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0733 - binary_accuracy: 0.9795 - val_loss: 0.4401 - val_binary_accuracy: 0.8736\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0599 - binary_accuracy: 0.9845 - val_loss: 0.4806 - val_binary_accuracy: 0.8692\n",
            "Epoch 11/20\n",
            "347/625 [===============>..............] - ETA: 1s - loss: 0.0504 - binary_accuracy: 0.9864"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLgBtfWLt4FM"
      },
      "source": [
        "#new model with only 1 dense layer\n",
        "l1 = tf.keras.layers.Embedding(HP_vocab_size, HP_embedding_dim)\n",
        "l2 = tf.keras.layers.GlobalAveragePooling1D()\n",
        "l3 = layers.Dense(1)\n",
        "layers_m2 = [l1,l2,l3]\n",
        "anothermodel = tf.keras.Sequential(layers_m2)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVZXB3ocuSUo"
      },
      "source": [
        "anothermodel.compile(loss= losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer='adam',\n",
        "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkXkaPEMu6vA"
      },
      "source": [
        "history2 = anothermodel.fit(train_ds, validation_data=val_ds, epochs=HP_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5rjqkiSvCC3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}